{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelas (file):\n",
    "    if 'ha' in file: dot=1\n",
    "    if 'na' in file: dot=2\n",
    "    if 'ca' in file: dot=3\n",
    "    if 'ra' in file: dot=4\n",
    "    if 'ka' in file: dot=5\n",
    "    if 'da' in file: dot=6\n",
    "    if 'ta' in file: dot=7\n",
    "    if 'sa' in file: dot=8\n",
    "    if 'wa' in file: dot=9\n",
    "    if 'la' in file: dot=10\n",
    "    if 'ma' in file: dot=11\n",
    "    if 'ga' in file: dot=12\n",
    "    if 'ba' in file: dot=13\n",
    "    if 'nga' in file: dot=14\n",
    "    if 'pa' in file: dot=15\n",
    "    if 'ja' in file: dot=16\n",
    "    if 'ya' in file: dot=17\n",
    "    if 'nya' in file: dot=18\n",
    "    return (dot-1)\n",
    "\n",
    "def minmax (img):#normalisasi min max\n",
    "    x,y = img.shape\n",
    "    balik = np.zeros(img.shape)\n",
    "    maks  = max(img.flatten())\n",
    "    mins = min(img.flatten())\n",
    "    for i in range(x):\n",
    "        for j in range (y):\n",
    "            balik[i,j]=(img[i,j]-mins)/(maks-mins)\n",
    "    return balik\n",
    "\n",
    "def scale (img):\n",
    "    return img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"D:\\\\data\"\n",
    "\n",
    "data = []\n",
    "label =[]\n",
    "\n",
    "for a in os.listdir(filepath):\n",
    "    for b in os.listdir(filepath + \"\\\\\" + str(a)):\n",
    "        img= cv2.imread(filepath + \"\\\\\" + str(a) + \"\\\\\" + str(b),0)#grayscale\n",
    "        x = cv2.resize(img,(64,64))#resize\n",
    "        x = scale(x)\n",
    "        data.append(x)\n",
    "        label.append(kelas (b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "label = np.array(label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x1,x2,y1,y2= train_test_split(data,label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160,) (8640,)\n"
     ]
    }
   ],
   "source": [
    "dtrain = np.array(x1)\n",
    "dlabel = np.array(y1)\n",
    "ttrain = np.array(x2)\n",
    "tlabel = np.array(y2)\n",
    "print(tlabel.shape, dlabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 64, 64, 1) (2160, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "fdtrain = np.reshape(dtrain,(8640,64,64,1))\n",
    "fttrain = np.reshape(ttrain,(2160,64,64,1))\n",
    "\n",
    "#fdtrain[:,:,:]= dtrain\n",
    "print(fdtrain.shape, fttrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (5, 5), activation='relu',padding='same', input_shape=(64, 64,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (5, 5),padding='same', activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (5, 5),padding='same', activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 128)       3328      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 128)       409728    \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                4194336   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 18)                594       \n",
      "=================================================================\n",
      "Total params: 4,607,986\n",
      "Trainable params: 4,607,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8640 samples, validate on 2160 samples\n",
      "Epoch 1/10\n",
      "8640/8640 [==============================] - 608s 70ms/sample - loss: 2.8905 - accuracy: 0.0561 - val_loss: 2.8919 - val_accuracy: 0.0477\n",
      "Epoch 2/10\n",
      "8640/8640 [==============================] - 526s 61ms/sample - loss: 2.8904 - accuracy: 0.0573 - val_loss: 2.8923 - val_accuracy: 0.0449\n",
      "Epoch 3/10\n",
      "8640/8640 [==============================] - 478s 55ms/sample - loss: 2.8904 - accuracy: 0.0566 - val_loss: 2.8924 - val_accuracy: 0.0449\n",
      "Epoch 4/10\n",
      "8640/8640 [==============================] - 483s 56ms/sample - loss: 2.8904 - accuracy: 0.0551 - val_loss: 2.8927 - val_accuracy: 0.0449\n",
      "Epoch 5/10\n",
      "8640/8640 [==============================] - 435s 50ms/sample - loss: 2.8904 - accuracy: 0.0582 - val_loss: 2.8927 - val_accuracy: 0.0449\n",
      "Epoch 6/10\n",
      "8640/8640 [==============================] - 451s 52ms/sample - loss: 2.8904 - accuracy: 0.0561 - val_loss: 2.8927 - val_accuracy: 0.0449\n",
      "Epoch 7/10\n",
      "8640/8640 [==============================] - 444s 51ms/sample - loss: 2.8904 - accuracy: 0.0565 - val_loss: 2.8927 - val_accuracy: 0.0449\n",
      "Epoch 8/10\n",
      "8640/8640 [==============================] - 452s 52ms/sample - loss: 2.8904 - accuracy: 0.0582 - val_loss: 2.8928 - val_accuracy: 0.0449\n",
      "Epoch 9/10\n",
      "8640/8640 [==============================] - 1332s 154ms/sample - loss: 2.8904 - accuracy: 0.0562 - val_loss: 2.8928 - val_accuracy: 0.0449\n",
      "Epoch 10/10\n",
      "8640/8640 [==============================] - 672s 78ms/sample - loss: 2.8904 - accuracy: 0.0582 - val_loss: 2.8928 - val_accuracy: 0.0449\n",
      "waktu training adalah :  5883.82844543457  s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.2)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])#, tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "mulai = time.time()\n",
    "history = model.fit(fdtrain,dlabel,\n",
    "    steps_per_epoch = 240,      \n",
    "    #batch_size=60,\n",
    "    epochs = 10,\n",
    "    validation_data = (fttrain,tlabel)\n",
    "    )\n",
    "print(\"waktu training adalah : \", time.time()-mulai , \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow",
   "language": "python",
   "name": "flow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
